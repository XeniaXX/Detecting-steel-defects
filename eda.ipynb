{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "cstaa2ft9i6i3ld0zi3fid"
   },
   "source": [
    "Мы будем предсказывать расположение и класс дефектов, обнаруженных на производстве стальных листов. Изображения имеют уникальные названия ImageId. Целью является сегментировать и классифицировать дефекты по изображениям из test датасета.<br>\n",
    "Каждое изображение может вообще не иметь дефектов, иметь дефект только одного класса или дефекты нескольких классов. Для каждого изображения нужно сегментировать дефекты каждого класса (ClassId = [1, 2, 3, 4])<br>\n",
    "Сегмент для дефекта каждого класса должен быть записан в отдельную строку, даже если на изображении присутствуют несколько дискретных расположений дефекта\n",
    "\n",
    "\n",
    "**Файлы** <br>\n",
    "- train_images/ - папка изображений для тренировки модели <br>\n",
    "- test_images/ - папка изображений для тестирования модели (мы сегментируем и классифицируем эти изображения)<br>\n",
    "- train.csv - аннотации с сегментами дефектов на изображениях из тренировочного датасета (ClassId = [1, 2, 3, 4])<br>\n",
    "- sample_submission.csv - a sample submission file in the correct format; <br>\n",
    "\n",
    "\n",
    "*note, each ImageId 4 rows, one for each of the 4 defect classes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "f5qogo8nojquq0zy7rjnhd"
   },
   "source": [
    "Пиксели номируются сверху вниз, потом слева направо, то есть 1й пиксель это $(0,0)$, 2й пиксель это $(1,0)$.<br>\n",
    "То есть если на картинке пиксель $(i,j)$, где $i$ - номер строки, $j$ - номер столбца, то его номер $n$ вычисляется по формуле $n = 256* j + i + 1$<br>\n",
    "Формула для вычисления i, j по порядковому номеру n:<br>\n",
    "$j = int(n/256)$<br>\n",
    "$i = n - 256*int(n/256) - 1 = n - 256*j -1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "bkg2c5ukz261ioeb0788m6",
    "execution_id": "bd426feb-4589-453e-a8bb-8cdef2ea4004"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "z605m376wyjc2hp00pwnbu",
    "execution_id": "5bce8a09-6bbe-4a27-8fda-fccb7aa22941",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "%pip install plotly\n",
    "%pip install -U protobuf==3.11.3\n",
    "%pip install seaborn\n",
    "%pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qnayvab2gtoqto6epwjkhn",
    "execution_id": "130904ed-daec-40af-bfb9-c3dde1b925c6"
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow h5py==2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "uef41dgtu2ixxlk55k24x",
    "execution_id": "9031fb3c-220f-4928-b29b-2962b0f20e10"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O\n",
    "import matplotlib.pyplot as plt # Import matplotlib for data visualisation\n",
    "import seaborn as sns\n",
    "#import pandas_profiling as pp\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import plotly\n",
    "from plotly import graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ocnnxs1ki3t0f66ach13",
    "execution_id": "f074180f-774d-426e-87ee-16eacf7c76eb"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "j9njbe92itjadecetkrc",
    "execution_id": "807d909b-1bc3-48a7-ab61-ce40fcc1780f"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"data\"))\n",
    "for dirname, _, filenames in os.walk('data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "vppg1hvz85jk8h9mbm5kgc",
    "execution_id": "1d57b41a-e06b-4d63-98fc-9c72cdb417eb"
   },
   "outputs": [],
   "source": [
    "#lets have a look at some images\n",
    "for dirname, _, filenames in os.walk('data'):\n",
    "    for filename in filenames[2:10]:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        im1 = imageio.imread(os.path.join(dirname, filename)) #Read the image from the desktop\n",
    "        print(im1.shape) #Returns the number of rows, columns and channels (if image is color returns \"3\")\n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.imshow(im1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "yxvv04kw4exelesc9ypn",
    "execution_id": "72dc051c-ab8c-4ea4-9ae4-f9dd60dfc610"
   },
   "outputs": [],
   "source": [
    "data_dir =\"data\"\n",
    "input_file0 = \"train.csv\"\n",
    "input_file1 = \"sample_submission.csv\"\n",
    "abspath='/'.join(os.getcwd().split('\\\\')) \n",
    "source_folder = os.path.join(abspath, 'data')\n",
    "df_train = pd.read_csv(os.path.join(source_folder,input_file0))\n",
    "df_sample = pd.read_csv(os.path.join(source_folder,input_file1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "app0uns6gx76mnmd0wpvya",
    "execution_id": "90a54cd7-27e8-4648-a21f-ec4677e856e6"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "24njbxpg0bssg6u2jbrwyb",
    "execution_id": "1490ebda-0908-49e0-b5ac-af9ca7cccfea"
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "2zp8lbozy1nweob098ag1p",
    "execution_id": "e0faad77-0e04-422a-a253-6e0f0947c540"
   },
   "outputs": [],
   "source": [
    "# Пути на папки с train_images и test_images соответственно\n",
    "trainImgPath =os.path.join(source_folder,'train_images/')\n",
    "testImgPath = os.path.join(source_folder,'test_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "d4xju194imwoy4ff4fajij",
    "execution_id": "23f5399c-6448-45d8-983d-d32d262c97c3"
   },
   "outputs": [],
   "source": [
    "# Создадим таблицу с ImageId из папки train_images\n",
    "# Каждому ImageId будут соответствовать 4 строки (для каждого класса дефекта)\n",
    "train_Img_Id = []\n",
    "train_class_Id = []\n",
    "for i in os.listdir(trainImgPath):\n",
    "    for j in range(1,5):\n",
    "        train_Img_Id.append(i)\n",
    "        train_class_Id.append(j)\n",
    "train_Imgs = pd.DataFrame(train_Img_Id,columns=['ImageId'])\n",
    "train_Imgs['ClassId'] = train_class_Id\n",
    "train_Imgs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "27ojnfuitu1rhwva5d7aem",
    "execution_id": "a98dd191-ee54-47cd-9039-f9e5161f28f6"
   },
   "outputs": [],
   "source": [
    "# Создадим таблицу - объединение 2х таблиц train_Img, df_train\n",
    "# Nan значения заменим пустыми строками\n",
    "train_d = pd.merge(train_Imgs, df_train,how='left', on=['ImageId','ClassId']) \n",
    "train_d = train_d.fillna('') \n",
    "train_d.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "y9rzp3og2ijqti7f2de1ka",
    "execution_id": "2972dd58-4d45-42d6-a8ec-43d0eb1cc695"
   },
   "outputs": [],
   "source": [
    "train_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50272/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tyi99tc2275a08vnf8ork",
    "execution_id": "64e5f6e9-22ea-4401-83e3-477d4643eee0"
   },
   "outputs": [],
   "source": [
    "# Изменим структуру таблицы:\n",
    "# каждому ImageId отвечает одна строка, а столбцы - это дефекты различных классов, если дефект какого-либо класса отсутствует, \n",
    "# то в соответствующем столбце - пустое значение\n",
    "train_data = pd.pivot_table(train_d, values='EncodedPixels', index='ImageId',columns='ClassId', aggfunc=np.sum).astype(str)\n",
    "train_data = train_data.reset_index() # add Index column to one level with classID   \n",
    "train_data.columns = ['ImageId','Defect_1','Defect_2','Defect_3','Defect_4']\n",
    "train_data.columns\n",
    "train_data = train_data.replace({'nan':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "iyy9drjvvqewv27ru0mjic",
    "execution_id": "a41e1868-503c-41fe-ac42-6cc11e8fb1a8"
   },
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(len(np.unique(train_data.ImageId.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "vcbifoxi4jg3yvcveutqf",
    "execution_id": "a3d6370a-180a-4bc6-af62-0f85233aaff4"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ec39pqx4g4an7zhk1ir6zl",
    "execution_id": "c3a34d41-44fe-4ca8-84a5-40b3ece9b3c3"
   },
   "outputs": [],
   "source": [
    "# Добавим колонки: \n",
    "# has_defect - индификатор наличия дефекта какого-либо класса, \n",
    "has_defect = []\n",
    "for index,row in train_data.iterrows():\n",
    "    if row.Defect_1 or row.Defect_2 or row.Defect_3 or row.Defect_4: \n",
    "        has_defect.append(1)\n",
    "    else:\n",
    "        has_defect.append(0)\n",
    "        \n",
    "train_data[\"has_defect\"] = has_defect \n",
    "number_of_defects=[]\n",
    "for index, row in train_data.iterrows():\n",
    "    i=0\n",
    "    if row.Defect_1:\n",
    "        i=i+1\n",
    "    if row.Defect_2:\n",
    "        i=i+1\n",
    "    if row.Defect_3:\n",
    "        i=i+1\n",
    "    if row.Defect_4:\n",
    "        i=i+1\n",
    "    number_of_defects.append(i)\n",
    "        \n",
    "train_data[\"number_of_defects\"] = number_of_defects  \n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "e1wbt9nsud5smtolgacsb",
    "execution_id": "e50c8511-f072-45a5-a601-38f011425844"
   },
   "outputs": [],
   "source": [
    "#Number of images with defects of several classes\n",
    "train_data[\"number_of_defects\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "v1wc5kkc21dl6s9vwzfqrj",
    "execution_id": "b964f2e4-037a-4f7f-b8e1-825d7a5c6fa7"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=list(train_data[\"number_of_defects\"].value_counts().index), y=list(train_data[\"number_of_defects\"].value_counts().values), ax=ax)\n",
    "ax.set_title(\"Number of images defects of number of classes\")\n",
    "ax.set_xlabel(\"Number of classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ozybhf7mjla6oyaj2l4og"
   },
   "source": [
    "Большинство изображений имеют дефекты одного класса (3909 экземпляров), дефекты двух классов имеют 242 изображений и нет ни одного изображающего, содержащего дефекты трех или всех четырех классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "yt2bg8cctkk65rxahux3ot",
    "execution_id": "11eb5598-15cb-4173-96a5-57086f51af5f"
   },
   "outputs": [],
   "source": [
    "# Number of images for each class\n",
    "class_count={}\n",
    "class_count['1'] = train_data[train_data['Defect_1']!=''].shape[0]\n",
    "class_count['2'] = train_data[train_data['Defect_2']!=''].shape[0]\n",
    "class_count['3'] = train_data[train_data['Defect_3']!=''].shape[0]\n",
    "class_count['4'] = train_data[train_data['Defect_4']!=''].shape[0]\n",
    "print('Class 1 ', class_count['1'])\n",
    "print('Class 2 ', class_count['2'])\n",
    "print('Class 3 ', class_count['3'])\n",
    "print('Class 4 ', class_count['4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "gt0g3j26658kga1llypcyl",
    "execution_id": "b60a21e0-fa9c-4e48-917e-38eeebbe536f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=list(class_count.keys()), y=list(class_count.values()), ax=ax)\n",
    "ax.set_title(\"Number of images for each class\")\n",
    "ax.set_xlabel(\"class\")\n",
    "class_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ofby03yapiogt2z4ie8lx"
   },
   "source": [
    "Преобладающим классом дефектов является класс 3, так как его содержат 5150 изображений. На втором месте находится класс 1 с 897 изображениями, на третьем - класс 4 (801 изображение). Меньше всего изображений, содержащих дефекты класса 2 - 247 изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "vxpyfa66nrpd31hw4h6p2w",
    "execution_id": "b96be6f0-4af0-499b-a730-2ccda8c3a1c9"
   },
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "grk4soqdvspmvnxoijto6l",
    "execution_id": "ae71ac0e-feeb-4719-b64f-1d9b6d787930"
   },
   "outputs": [],
   "source": [
    "train_data.has_defect.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jum5fxsgiz8vs68xutxt6",
    "execution_id": "e1d55186-5f37-4aa4-95c0-3e0667417651"
   },
   "outputs": [],
   "source": [
    "def mask_to_rle(mask):\n",
    "    \"\"\"\n",
    "    params:  mask - numpy array\n",
    "    returns: run-length encoding string (pairs of start & length of encoding)\n",
    "    \"\"\"\n",
    "    \n",
    "    # turn a n-dimensional array into a 1-dimensional series of pixels\n",
    "    # for example:\n",
    "    #     [[1. 1. 0.]\n",
    "    #      [0. 0. 0.]   --> [1. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
    "    #      [1. 0. 0.]]\n",
    "    flat = mask.flatten()\n",
    "    \n",
    "    # we find consecutive sequences by overlaying the mask\n",
    "    # on a version of itself that is displaced by 1 pixel\n",
    "    # for that, we add some padding before slicing\n",
    "    padded = np.concatenate([[0], flat, [0]])\n",
    "    \n",
    "    # this returns the indices where the sliced arrays differ\n",
    "    runs = np.where(padded[1:] != padded[:-1])[0] \n",
    "    # indexes start at 0, pixel numbers start at 1\n",
    "    runs += 1\n",
    "\n",
    "    # every uneven element represents the start of a new sequence\n",
    "    # every even element is where the run comes to a stop\n",
    "    # subtract the former from the latter to get the length of the run\n",
    "    runs[1::2] -= runs[0::2]\n",
    " \n",
    "    # convert the array to a string\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "8l6quy8x9uaplxpymh4a6l",
    "execution_id": "5df907d1-7839-44dd-abe3-2e69e944056c"
   },
   "outputs": [],
   "source": [
    "a=np.array([[0., 0., 1.],[0., 1., 0.],[0., 0., 1.]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "do28fzjuaei72ig7grmg6f",
    "execution_id": "0433e56d-c771-4236-b8b7-eb2bb3bd14b2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask_to_rle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "fb22y2tox8fybq6fi8nm6",
    "execution_id": "04aa72a1-b47a-4c03-97cb-4f9ffe124b8d"
   },
   "outputs": [],
   "source": [
    "def rle_to_mask(lre, shape=(1600, 256)):\n",
    "    '''\n",
    "    params:  rle   - run-length encoding string (pairs of start & length of encoding)\n",
    "             shape - (width,height) of numpy array to return \n",
    "    \n",
    "    returns: numpy array with dimensions of shape parameter\n",
    "    '''    \n",
    "    h, w = shape\n",
    "    if len(lre)>0:# the incoming string is space-delimited\n",
    "        runs = np.asarray([int(run) for run in lre.split(' ')])\n",
    "\n",
    "        # we do the same operation with the even and uneven elements, but this time with addition\n",
    "        runs[1::2] += runs[0::2]\n",
    "        # pixel numbers start at 1, indexes start at 0\n",
    "        runs -= 1\n",
    "\n",
    "        # extract the starting and ending indeces at even and uneven intervals, respectively\n",
    "        run_starts, run_ends = runs[0::2], runs[1::2]\n",
    "\n",
    "        # build the mask\n",
    "        mask = np.zeros(h*w, dtype=np.uint8)\n",
    "        for start, end in zip(run_starts, run_ends):\n",
    "            mask[start:end] = 1\n",
    "    elif len(lre)==0:\n",
    "        mask = np.zeros(h*w, dtype=np.uint8)\n",
    "    # transform the numpy array from flat to the original image shape\n",
    "    return mask.reshape(shape).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ymft1iiyrrcsf1mhpb8g",
    "execution_id": "c4419d4c-9b1a-4315-818f-375cbb62b7e0"
   },
   "outputs": [],
   "source": [
    "rle_to_mask('3 3 7 2', shape=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "wi9vzlswgqz13ey7znsp7",
    "execution_id": "b2b0a3be-9341-4bf0-8d99-6e8864b0dc64"
   },
   "outputs": [],
   "source": [
    "rle_to_mask('', shape=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "r327nd2ojdfrdzng2gbwt",
    "execution_id": "14ef6404-2609-445b-9e4e-03ee78fcd73e"
   },
   "outputs": [],
   "source": [
    "def load_img(img_id):\n",
    "    img_dir='train_images' \n",
    "    img = cv2.imread(os.path.join(os.path.join(data_dir,img_dir), img_id))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "re0ctukriadqnjixrs8x",
    "execution_id": "ba0836e8-e8c2-4248-93bd-5f8a26a69d3b"
   },
   "outputs": [],
   "source": [
    "rgb_for_label = {i:v for i, v in enumerate([(0, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)], start=1)}\n",
    "\n",
    "    \n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 5))\n",
    "for i in range(0, 4):\n",
    "    ax[i].axis('off')\n",
    "    ax[i].imshow(np.ones((50, 50, 3), dtype=np.uint8) * rgb_for_label[i+1])\n",
    "    ax[i].set_title(\"class color: {}\".format(i+1))\n",
    "fig.suptitle(\"Colors for the classes\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "f20lu606r66zbnrlz9nsm",
    "execution_id": "7a69be3c-1933-4903-bfc1-7e42595fc125"
   },
   "outputs": [],
   "source": [
    "def show_masked_image(img_id, ax=None, thickness=2):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    \n",
    "    img = load_img(img_id)\n",
    "    for i, col in df_train[df_train['ImageId'] == img_id].iterrows():\n",
    "        encoded_pixels = col['EncodedPixels']\n",
    "        label = col['ClassId']\n",
    "        mask = rle_to_mask(encoded_pixels, shape=(1600, 256))\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        img = cv2.drawContours(img, contours, -1, rgb_for_label[label], thickness=thickness)\n",
    "    ax.imshow(img)\n",
    "    return ax\n",
    "\n",
    "#def show_masked_images_per_class(label, num_images=5):\n",
    "\n",
    "    #num_imgs = 5\n",
    "    #fig, axs = plt.subplots(nrows=num_imgs, ncols=1, figsize=(15, 15))\n",
    "    #axs = axs.ravel()\n",
    "    \n",
    "    #image_ids = np.asarray(train_data[train_data['Defect_1']!='']['ImageId'].values)\n",
    "    #random_ids = list(image_ids)[:5]\n",
    "    \n",
    "    #for i, img_id in enumerate(image_ids[random_ids]):\n",
    "        #show_masked_image(img_id, ax=axs[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qm5gsk0d8oeprawgbmk4t",
    "execution_id": "b21705ad-3ad8-46cf-b80b-65aad23b2bd5"
   },
   "outputs": [],
   "source": [
    "#Без дефектов\n",
    "show_masked_image('000789191.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tigkllq3p3kib3ed8mbq",
    "execution_id": "b468def1-624c-488a-895e-844e1239c56f"
   },
   "outputs": [],
   "source": [
    "show_masked_image('001982b08.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "prtymr2c0jhyyad1qzgers"
   },
   "source": [
    "## Аналитика изображений с дефектами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ie0ffwlcdr8095bv9j39wrk",
    "execution_id": "61852ca3-f353-46df-8fa4-561690dc2378"
   },
   "outputs": [],
   "source": [
    "#Первые 10 изображений с дефектами класса 1\n",
    "train_data[train_data['Defect_1']!=''].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "kl1j7squyts2zq288p1z",
    "execution_id": "2eb9a0a0-c44e-4403-b289-3af640cd56a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Пример изображения с дефектом класса 1\n",
    "filename='000a4bcdd.jpg'\n",
    "img_dir='train_images'\n",
    "img = imageio.imread(os.path.join(os.path.join(data_dir,img_dir), filename)) #Read the image from the desktop\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "show_masked_image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "n830457h1bfkwvd32tqpk",
    "execution_id": "edaef511-6ce1-4810-952f-d1084d7b3c1f"
   },
   "outputs": [],
   "source": [
    "filename='00bc01bfe.jpg'\n",
    "img_dir='train_images'\n",
    "img = imageio.imread(os.path.join(os.path.join(data_dir,img_dir), filename)) #Read the image from the desktop\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.show()\n",
    "show_masked_image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "nyho8yzd2hezeef6jhpf8h",
    "execution_id": "d753b884-04ea-4312-8d71-9d75a3cf3fdc"
   },
   "outputs": [],
   "source": [
    "#Первые 10 изображений с дефектами класса 2\n",
    "train_data[train_data['Defect_2']!=''].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ly074u43nke7orjtvwpdv",
    "execution_id": "d84729de-a319-4256-9381-284ea920021c"
   },
   "outputs": [],
   "source": [
    "#Пример изображения с дефектом класса 2\n",
    "filename='026183d85.jpg'\n",
    "img_dir='train_images'\n",
    "img = imageio.imread(os.path.join(os.path.join(data_dir,img_dir), filename)) #Read the image from the desktop\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.show()\n",
    "show_masked_image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "mn2tai2ygqlk2epf8muooo",
    "execution_id": "2372e164-741f-4b3e-bc95-3ecce0d9d959"
   },
   "outputs": [],
   "source": [
    "filename='068c6c4a9.jpg'\n",
    "img_dir='train_images'\n",
    "img = imageio.imread(os.path.join(os.path.join(data_dir,img_dir), filename)) #Read the image from the desktop\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.show()\n",
    "show_masked_image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "193q5r5gfnvjm1afy0z1s",
    "execution_id": "0e647e2c-4842-4863-b8cd-5f993d18e6a3"
   },
   "outputs": [],
   "source": [
    "#Первые 10 изображений с дефектами класса 3\n",
    "train_data[train_data['Defect_3']!=''].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9j4virbidm8mp1grvhvxjd",
    "execution_id": "f6309a7f-5c30-4f05-8901-3e10255c92c4"
   },
   "outputs": [],
   "source": [
    "#Пример изображения с дефектом класса 3\n",
    "filename='005f19695.jpg'\n",
    "img_dir='train_images'\n",
    "img = imageio.imread(os.path.join(os.path.join(data_dir,img_dir), filename)) #Read the image from the desktop\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.show()\n",
    "show_masked_image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "b5r6tdo40m41i5mwqfw3fp",
    "execution_id": "2cbda381-6f1c-44a2-bf11-9dbe18390d48"
   },
   "outputs": [],
   "source": [
    "filename='008d0f87b.jpg'\n",
    "img_dir='train_images'\n",
    "img = imageio.imread(os.path.join(os.path.join(data_dir,img_dir), filename)) #Read the image from the desktop\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.show()\n",
    "show_masked_image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "gr2x6hyv96zkif9ewtv4m",
    "execution_id": "dcfde109-1b8a-4af3-bfa8-defdda4050a4"
   },
   "outputs": [],
   "source": [
    "#Первые 10 изображений с дефектами класса 4\n",
    "train_data[train_data['Defect_4']!=''].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "7h56kbo557tcd8ocf3ipy5",
    "execution_id": "2da004ba-c7d8-4f2c-8b26-7cc463a7ecd8"
   },
   "outputs": [],
   "source": [
    "#Пример изображения с дефектом класса 4\n",
    "filename='008621629.jpg'\n",
    "img_dir='train_images'\n",
    "img = imageio.imread(os.path.join(os.path.join(data_dir,img_dir), filename)) #Read the image from the desktop\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.show()\n",
    "show_masked_image(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qizlb2zhrr9mbpyy7zzz",
    "execution_id": "a6e58baf-25ff-44ca-9d45-00502abd8892",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename='038f14456.jpg'\n",
    "img_dir='train_images'\n",
    "img = imageio.imread(os.path.join(os.path.join(data_dir,img_dir), filename)) #Read the image from the desktop\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.show()\n",
    "show_masked_image(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "b8a1w0qkaaop9cpdcj15y"
   },
   "source": [
    "### Размер mask для классов дефектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "pmbj8n0xozkqq3fva4jibf"
   },
   "source": [
    "Так как у нас бинарные masks (1 или 0), то мы можем посчитать число пикселей с дефектом (где 1) в маске, чтобы как-то оценить размер дефектов каждого класса и посмотреть как это зависит от класса дефекта. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "668f9upd9pjmnjhc9zukr",
    "execution_id": "b2606db1-3885-443c-a3d1-3fcf02c9002f"
   },
   "outputs": [],
   "source": [
    "# Посчитаем сумму пикселей с 1 в маске для каждого класса (class id)\n",
    "df_train['ClassId_str'] = df_train['ClassId'].astype(str)\n",
    "\n",
    "df_train['mask_pixel_sum'] = df_train.apply(lambda x: rle_to_mask(x['EncodedPixels']).sum(), axis=1)\n",
    "\n",
    "class_ids = [str(i) for i in range(1, 5)]\n",
    "mask_count_per_class = [df_train[(df_train['ClassId_str']==class_id)&(df_train['mask_pixel_sum']!=0)]['mask_pixel_sum'].count() for class_id in class_ids]\n",
    "pixel_sum_per_class = [df_train[(df_train['ClassId_str']==class_id)&(df_train['mask_pixel_sum']!=0)]['mask_pixel_sum'].sum() for class_id in class_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "g22n6i9dt9ytmxpeeh2zm",
    "execution_id": "f12a773c-0527-41bb-a4b5-7d7e0c576258"
   },
   "outputs": [],
   "source": [
    "mask_count_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "rlcrgrre8qnrdvegrtgq4r",
    "execution_id": "1089a80b-6c5a-4b7d-ae57-113bbfcbf056"
   },
   "outputs": [],
   "source": [
    "pixel_sum_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "r1hh4k1x6yog67tj647juv",
    "execution_id": "b25a378b-c9cc-44a6-8ad2-bea8bf35eba0"
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "020ia85en3o47ofyqmzhqwf",
    "execution_id": "54471b6e-1d60-4702-98b7-b3c8bad867c1"
   },
   "outputs": [],
   "source": [
    "# Построим pie chart (справа - число изображений, содержащих дефекты данного класса)\n",
    "# Слева - Суммарное число пикселей, содержащих дефекты данного класса\n",
    "import plotly.subplots\n",
    "fig = plotly.subplots.make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "\n",
    "fig.add_trace(go.Pie(labels=class_ids, values=mask_count_per_class, name=\"Mask Count\"), 1, 1)\n",
    "fig.add_trace(go.Pie(labels=class_ids, values=pixel_sum_per_class, name=\"Pixel Count\"), 1, 2)\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig.update_traces(hole=.4, hoverinfo=\"label+percent+name\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Steel Defect Mask & Pixel Count\",\n",
    "    # Add annotations in the center of the donut pies.\n",
    "    annotations=[dict(text='Count', x=0.18, y=0.5, font_size=20, showarrow=False),\n",
    "                 dict(text='Sum', x=0.80, y=0.5, font_size=20, showarrow=False)])\n",
    "fig['layout'].update(height=400, width=900, title='Pixel count and sum per class mask', legend={'traceorder':'normal'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "q1y954u679ee70aqltdub8",
    "execution_id": "d68a600f-76b3-4037-8b1b-545a3b638a94"
   },
   "outputs": [],
   "source": [
    "# Построим гистограмму и box plot\n",
    "fig = px.histogram(df_train[df_train['mask_pixel_sum']!=0][['ClassId','mask_pixel_sum']], \n",
    "                   x=\"mask_pixel_sum\", y=\"ClassId\", color=\"ClassId\", marginal=\"box\")\n",
    "\n",
    "fig['layout'].update(height=400, width=900,title='Histogram and Boxplot of Sum of Mask Pixels Per Class')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "eyhz302cqbngs3wc5fqiqd"
   },
   "source": [
    "Из гистограммы и box plot можно подтвердить, что дефекты класса 4 обычно больше по размеру, чем дефекты класса 3, и очевидно дефекты классов 1 и 2. Дефекты класса 3 содержат больше outliers. </br>\n",
    "\n",
    "Несмотря на то, что дефекты класса 4 обычно больше по размеру, чем дефекты класса 3, outliers класса 3 могут значительно превышать по размеру дефекты класса 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "yem9b0n2bsg3rfud9bdo"
   },
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3i7lt6krp2rbcbq3uwjx7j",
    "execution_id": "918ecb23-fd01-4553-8563-c4cee58bfcf5"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3jo834gqu7p5rlhxc8w202",
    "execution_id": "9703a655-4d51-4dc3-99a2-e24c59b675c6"
   },
   "outputs": [],
   "source": [
    "path=source_folder+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "5ole2vv4rq5z5yyi307t5r",
    "execution_id": "de1034d8-98b6-44f8-91c9-517f8206a06a"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size = 16, subset=\"train\", shuffle=False, preprocess=None, info={}):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.shuffle = shuffle\n",
    "        self.subset = subset\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocess = preprocess\n",
    "        self.info = info\n",
    "        \n",
    "        if self.subset == \"train\":\n",
    "            self.data_path = os.path.join(source_folder,'train_images/')\n",
    "        elif self.subset == \"test\":\n",
    "            self.data_path = os.path.join(source_folder,'test_images/')\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.df))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __getitem__(self, index): \n",
    "        X = np.empty((self.batch_size,128,800,3),dtype=np.float32)\n",
    "        y = np.empty((self.batch_size,128,800,4),dtype=np.int8)\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n",
    "            self.info[index*self.batch_size+i]=f\n",
    "            X[i,] = Image.open(os.path.join(self.data_path, f)).resize((800,128))\n",
    "            if self.subset == 'train': \n",
    "                for j in range(4):\n",
    "                    y[i,:,:,j] = rle2maskResize(self.df['Defect_'+str(j+1)].iloc[indexes[i]])\n",
    "        if self.preprocess!=None: X = self.preprocess(X)\n",
    "        if self.subset == 'train': return X, y\n",
    "        else: return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "569ngs35e7q4koniu2bp6p",
    "execution_id": "9e31b5ed-7a6f-4cfc-993b-5818c2f0bb0c"
   },
   "outputs": [],
   "source": [
    "def rle2maskResize(rle):\n",
    "    \"\"\"\n",
    "    Convert run length encoding to mask\n",
    "    \"\"\"\n",
    "    if (pd.isnull(rle))|(rle==''): \n",
    "        return np.zeros((128,800) ,dtype=np.uint8)\n",
    "    \n",
    "    height= 256\n",
    "    width = 1600\n",
    "    mask= np.zeros( width*height ,dtype=np.uint8)\n",
    "\n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]-1\n",
    "    lengths = array[1::2]    \n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 1\n",
    "    \n",
    "    return mask.reshape( (height,width), order='F' )[::2,::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "029hwuhatwxxv2567wbo9k",
    "execution_id": "528ac637-564c-4612-a0d1-14dd2f10ac01"
   },
   "outputs": [],
   "source": [
    "def mask2contour(mask, width=3):\n",
    "    \"\"\"\n",
    "    Convert mask to its contour\n",
    "    \"\"\"\n",
    "    w = mask.shape[1]\n",
    "    h = mask.shape[0]\n",
    "    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n",
    "    mask2 = np.logical_xor(mask,mask2)\n",
    "    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n",
    "    mask3 = np.logical_xor(mask,mask3)\n",
    "    return np.logical_or(mask2,mask3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "bk73kt4rfup7dgf5uylh7k",
    "execution_id": "e03fc3d0-b628-44b0-8148-96a4fd918c1f"
   },
   "outputs": [],
   "source": [
    "\n",
    "mask2contour(a, width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "lhufmphgk5brw5mrirvp7",
    "execution_id": "02cc9e56-35cb-4808-aed8-6a8bb33310cf"
   },
   "outputs": [],
   "source": [
    "rle2maskResize('3 3 7 2').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "slbi7cy66v0s4ixce20s49",
    "execution_id": "2bdf2d0c-eca6-4d0d-932c-88cfde59b517"
   },
   "outputs": [],
   "source": [
    "def mask2pad(mask, pad=2):\n",
    "    \"\"\"\n",
    "    Enlarge Mask to include more space around the defect\n",
    "    \"\"\"\n",
    "    w = mask.shape[1]\n",
    "    h = mask.shape[0]\n",
    "    \n",
    "    # MASK UP\n",
    "    for k in range(1,pad,2):\n",
    "        temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n",
    "        mask = np.logical_or(mask,temp)\n",
    "    # MASK DOWN\n",
    "    for k in range(1,pad,2):\n",
    "        temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n",
    "        mask = np.logical_or(mask,temp)\n",
    "    # MASK LEFT\n",
    "    for k in range(1,pad,2):\n",
    "        temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n",
    "        mask = np.logical_or(mask,temp)\n",
    "    # MASK RIGHT\n",
    "    for k in range(1,pad,2):\n",
    "        temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n",
    "        mask = np.logical_or(mask,temp)\n",
    "    \n",
    "    return mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3vvgmhcjl7guwl1g8dkm7",
    "execution_id": "af5f69e0-a14c-4db9-a3c3-6ec8a74d3923"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "gwjxomvoig7fibjkbdwre",
    "execution_id": "5c96f264-8709-418e-8543-da2068f6a578"
   },
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "e458swfgrswexbro6p4cd",
    "execution_id": "ce9c418f-92bc-4de9-a7dd-54be9163fad0"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13.5,2.5))\n",
    "bar = plt.bar( [1,2,3,4],100*np.mean( train_data.iloc[:,1:5]!='',axis=0) )\n",
    "plt.title('Percent Training Images with Defect', fontsize=16)\n",
    "plt.ylabel('Percent of Images'); plt.xlabel('Defect Type')\n",
    "plt.xticks([1,2,3,4])\n",
    "for rect in bar:\n",
    "    height = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.1f %%' % height,\n",
    "             ha='center', va='bottom',fontsize=16)\n",
    "plt.ylim((0,100)); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "wbmrp5koa8hpvuprcxevs"
   },
   "outputs": [],
   "source": [
    "# DEFECTIVE IMAGE SAMPLES\n",
    "filenames = {}\n",
    "defects = list(train_data[train_data['Defect_1']!=''].sample(3).index)\n",
    "defects += list(train_data[train_data['Defect_2']!=''].sample(3).index)\n",
    "defects += list(train_data[train_data['Defect_3']!=''].sample(7).index)\n",
    "defects += list(train_data[train_data['Defect_4']!=''].sample(3).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "5dp4mp06cdcymy2ktj9lv"
   },
   "outputs": [],
   "source": [
    "# DATA GENERATOR\n",
    "train_batches = DataGenerator(train_data[train_data.index.isin(defects)],shuffle=True,info=filenames)\n",
    "print('Images and masks from our Data Generator')\n",
    "print('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "axnic4wdkle3vs8g9g1m2u",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DISPLAY IMAGES WITH DEFECTS\n",
    "for i,batch in enumerate(train_batches):\n",
    "    plt.figure(figsize=(14,50)) #20,18\n",
    "    for k in range(16):\n",
    "        plt.subplot(16,1,k+1)\n",
    "        img = batch[0][k,]\n",
    "        img = Image.fromarray(img.astype('uint8'))\n",
    "        img = np.array(img)\n",
    "        extra = '  has defect'\n",
    "        for j in range(4):\n",
    "            msk = batch[1][k,:,:,j]\n",
    "            msk = mask2pad(msk,pad=3)\n",
    "            msk = mask2contour(msk,width=2)\n",
    "            if np.sum(msk)!=0: extra += ' '+str(j+1)\n",
    "            if j==0: # yellow\n",
    "                img[msk==1,0] = 235 \n",
    "                img[msk==1,1] = 235\n",
    "            elif j==1: img[msk==1,1] = 210 # green\n",
    "            elif j==2: img[msk==1,2] = 255 # blue\n",
    "            elif j==3: # magenta\n",
    "                img[msk==1,0] = 255\n",
    "                img[msk==1,2] = 255\n",
    "        plt.title(filenames[16*i+k]+extra)\n",
    "        plt.axis('off') \n",
    "        plt.imshow(img)\n",
    "    plt.subplots_adjust(wspace=0.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "AUGMENT_BRIGHTNESS=False\n",
    "# ImageDataGenerator\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 45, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.2, 1.25],  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "# brightness can be problematic since it seems to change the labels differently from the images \n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args['brightness_range'] = [0, 0.1]\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args.pop('brightness_range')\n",
    "label_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        for i in range(9):\n",
    "            seed = np.random.choice(range(9999))\n",
    "            # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
    "            g_x = image_gen.flow(255*in_x, \n",
    "                                 batch_size = in_x.shape[0], \n",
    "                                 seed = seed, \n",
    "                                 shuffle=True)\n",
    "            g_y = label_gen.flow(in_y, \n",
    "                                 batch_size = in_x.shape[0], \n",
    "                                 seed = seed, \n",
    "                                 shuffle=True)\n",
    "\n",
    "            yield next(g_x)/255.0, next(g_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY IMAGES WITH DEFECTS\n",
    "for i,batch in enumerate(create_aug_gen(train_batches)):\n",
    "    plt.figure(figsize=(14,50)) #20,18\n",
    "    for k in range(16):\n",
    "        plt.subplot(16,1,k+1)\n",
    "        img = batch[0][k,]\n",
    "        img = Image.fromarray(img.astype('uint8'))\n",
    "        img = np.array(img)\n",
    "        extra = '  has defect'\n",
    "        for j in range(4):\n",
    "            msk = batch[1][k,:,:,j]\n",
    "            msk = mask2pad(msk,pad=3)\n",
    "            msk = mask2contour(msk,width=2)\n",
    "            if np.sum(msk)!=0: extra += ' '+str(j+1)\n",
    "            if j==0: # yellow\n",
    "                img[msk==1,0] = 235 \n",
    "                img[msk==1,1] = 235\n",
    "            elif j==1: img[msk==1,1] = 210 # green\n",
    "            elif j==2: img[msk==1,2] = 255 # blue\n",
    "            elif j==3: # magenta\n",
    "                img[msk==1,0] = 255\n",
    "                img[msk==1,2] = 255\n",
    "        #plt.title(filenames[16*i+k]+extra)\n",
    "        plt.axis('off') \n",
    "        plt.imshow(img)\n",
    "    plt.subplots_adjust(wspace=0.05)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "0muaganacvzlo0pzqb2lgvg"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Compute Dice Coefficient\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "6s8kbzxfzinkffpm88asc"
   },
   "outputs": [],
   "source": [
    "%pip install segmentation_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "zjv5hlcpvtr0i9odv647"
   },
   "outputs": [],
   "source": [
    "%env SM_FRAMEWORK=tf.keras\n",
    "from segmentation_models import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!L\n",
    "# Load U-Net pretrained from ImageNet\n",
    "#%enable_full_walk\n",
    "# Train and validate the model\n",
    "import tensorflow.keras as keras\n",
    "idx = int(0.8*len(train_data)); print()\n",
    "train_batches = DataGenerator(train_data.iloc[:idx],shuffle=True)\n",
    "valid_batches = DataGenerator(train_data.iloc[idx:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('severstal_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "dpingdo863h9nqo9tqenk"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# Load U-Net pretrained from ImageNet\n",
    "#%enable_full_walk\n",
    "# Train and validate the model\n",
    "import tensorflow.keras as keras\n",
    "idx = int(0.8*len(train_data)); print()\n",
    "train_batches = DataGenerator(train_data.iloc[:idx],shuffle=True)\n",
    "valid_batches = DataGenerator(train_data.iloc[idx:])\n",
    "\n",
    "\n",
    "model = Unet('resnet34', input_shape=(128, 800, 3), classes=4, activation='sigmoid')\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.33,\n",
    "                                   patience=1, verbose=1, mode='min',\n",
    "                                   min_delta=0.0001, cooldown=0, min_lr=1e-8)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=2,\n",
    "                      patience=20) # probably needs to be more patient, but kaggle time is limited\n",
    "\n",
    "#model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "   # filepath=checkpoint_filepath,\n",
    "   # save_weights_only=True,\n",
    "    #monitor='val_accuracy',\n",
    "    #mode='max',\n",
    "    #save_best_only=True)\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "def fit():\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
    "    \n",
    "    #step_count = min(MAX_TRAIN_STEPS, train_df.shape[0]//BATCH_SIZE)\n",
    "    aug_gen = create_aug_gen(train_batches)\n",
    "    loss_history = [model.fit_generator(aug_gen, \n",
    "                                        validation_data = valid_batches,\n",
    "                                        epochs = 100, verbose=2,\n",
    "                                        callbacks=callbacks_list)]\n",
    "    return loss_history\n",
    "\n",
    "while True:\n",
    "    history = fit()\n",
    "    if np.min([mh.history['val_loss'] for mh in loss_history]) < -0.2:\n",
    "        break\n",
    "\n",
    "\n",
    "#model.summary()\n",
    "#history = model.fit_generator(train_batches, validation_data = valid_batches, epochs = 100, verbose=2)\n",
    "\n",
    "# SAVE MODEL\n",
    "model.load_weights(weight_path)\n",
    "model.save('UNET34.h5')\n",
    "# Plot training\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(history.epoch[-1]+1),history.history['val_dice_coef'],label='val_dice_coef')\n",
    "plt.plot(range(history.epoch[-1]+1),history.history['dice_coef'],label='trn_dice_coef')\n",
    "plt.title('Training Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Dice_coef');plt.legend(); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3y5wp4h91nl9k56qf24efc"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# PREDICT FROM VALIDATION SET\n",
    "%enable_full_walk\n",
    "#idx = int(0.8*len(train_data)); print()\n",
    "val_set = train_data.iloc[idx:];\n",
    "defects = list(val_set[val_set['Defect_1']!=''].sample(6).index)\n",
    "defects += list(val_set[val_set['Defect_2']!=''].sample(6).index)\n",
    "defects += list(val_set[val_set['Defect_3']!=''].sample(14).index)\n",
    "defects += list(val_set[val_set['Defect_4']!=''].sample(6).index)\n",
    "valid_batches = DataGenerator(val_set[val_set.index.isin(defects)])\n",
    "preds = model.predict_generator(valid_batches,verbose=1)\n",
    "# PLOT PREDICTIONS\n",
    "valid_batches = DataGenerator(val_set[val_set.index.isin(defects)])\n",
    "print('Plotting predictions...')\n",
    "print('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\n",
    "\n",
    "for i,batch in enumerate(valid_batches):\n",
    "    plt.figure(figsize=(20,36))\n",
    "    for k in range(16):\n",
    "        plt.subplot(16,2,2*k+1)\n",
    "        img = batch[0][k,]\n",
    "        img = Image.fromarray(img.astype('uint8'))\n",
    "        img = np.array(img)\n",
    "        dft = 0\n",
    "        extra = '  has defect '\n",
    "        for j in range(4):\n",
    "            msk = batch[1][k,:,:,j]\n",
    "            if np.sum(msk)!=0: \n",
    "                dft=j+1\n",
    "                extra += ' '+str(j+1)\n",
    "            msk = mask2pad(msk,pad=2)\n",
    "            msk = mask2contour(msk,width=3)\n",
    "            if j==0: # yellow\n",
    "                img[msk==1,0] = 235 \n",
    "                img[msk==1,1] = 235\n",
    "            elif j==1: img[msk==1,1] = 210 # green\n",
    "            elif j==2: img[msk==1,2] = 255 # blue\n",
    "            elif j==3: # magenta\n",
    "                img[msk==1,0] = 255\n",
    "                img[msk==1,2] = 255\n",
    "        if extra=='  has defect ': extra =''\n",
    "        plt.title('Train '+train_data.iloc[16*i+k,0]+extra)\n",
    "        plt.axis('off') \n",
    "        plt.imshow(img)\n",
    "        plt.subplot(16,2,2*k+2) \n",
    "        if dft!=0:\n",
    "            msk = preds[16*i+k,:,:,dft-1]\n",
    "            plt.imshow(msk)\n",
    "        else:\n",
    "            plt.imshow(np.zeros((128,800)))\n",
    "        plt.axis('off')\n",
    "        mx = np.round(np.max(msk),3)\n",
    "        plt.title('Predict Defect '+str(dft)+'  (max pixel = '+str(mx)+')')\n",
    "    plt.subplots_adjust(wspace=0.05)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "02w6acx1fhi6qxrys4sb54o"
   },
   "source": [
    "We will plot histograms showing the predicted size of each defect mask. We would hope that if an image does not have a particular defect then UNET would not predict a mask (i.e. predict less than 250 pixel mask). This is not the case. When UNET predicts a mask when a defect isn't present, we call that an \"incorrect\" mask. When UNET predicts a mask when a defect is present, we call that a \"correct\" mask. If UNET predicts less than 250 pixels, we will treat that as no mask predicted. Let's compare the distribution of \"incorrect\" versus \"correct\" masks for each defect type.\n",
    "\n",
    "UNET outputs masks using all floating point values between 0 and 1 inclusive. For this classification problem, we need to use only integer 0 and 1. Therefore we must convert mask floating points into integers using a threshold. If pixel>=THRESHOLD then pixel=1 else pixel=0. We will plot histograms for various thresholds below. We will consider all masks with less than 250 pixels as empty masks (where pixel_count = 4 * pixel count on 128x800)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jck3bu16vpomy0u10yk4ai"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# PLOT RESULTS\n",
    "import seaborn as sns\n",
    "pix_min = 250\n",
    "for THRESHOLD in [0.1, 0.25, 0.50, 0.75, 0.9]:\n",
    "    print('######################################')\n",
    "    print('## Threshold =',THRESHOLD,'displayed below ##')\n",
    "    print('######################################')\n",
    "    correct=[[],[],[],[]]; incorrect=[[],[],[],[]]\n",
    "    for i,f in enumerate(train_data.iloc[idx:idx+len(preds)]['ImageId']):\n",
    "        preds2 = preds[i].copy()\n",
    "        preds2[preds2>=THRESHOLD]=1\n",
    "        preds2[preds2<THRESHOLD]=0\n",
    "        sums = np.sum(preds2,axis=(0,1))\n",
    "        for j in range(4):\n",
    "            if 4*sums[j]<pix_min: continue\n",
    "            if train_data.iloc[i,j+1]=='': incorrect[j].append(4*sums[j])\n",
    "            else: correct[j].append(4*sums[j])\n",
    "    plt.figure(figsize=(20,8))\n",
    "    for j in range(4):\n",
    "        limit = [10000,10000,100000,100000][j]\n",
    "        plt.subplot(2,2,j+1)\n",
    "        sns.distplot([x for x in correct[j] if x<limit], label = 'correct')\n",
    "        sns.distplot([x for x in incorrect[j] if x<limit], label = 'incorrect')\n",
    "        plt.title('Defect '+str(j+1)+' mask sizes with threshold = '+str(THRESHOLD)); plt.legend()\n",
    "    plt.show()\n",
    "    for j in range(4):\n",
    "        c1 = np.array(correct[j])\n",
    "        c2 = np.array(incorrect[j])\n",
    "        print('With threshold =',THRESHOLD,', defect',j+1,'has',len(c1[c1!=0]),'correct and',len(c2[c2!=0]),'incorrect masks')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "esaaidyy3as1mdjeifm8r"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# LOAD MODEL\n",
    "%enable_full_walk\n",
    "from tensorflow.keras.models import load_model\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Compute Dice Coefficient\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "model = load_model('UNET.h5',custom_objects={'dice_coef':dice_coef})\n",
    "\n",
    "# PREDICT 1 BATCH TEST DATASET\n",
    "test = pd.read_csv(path + 'sample_submission.csv')\n",
    "# test['ImageId'] = test['ImageId_ClassId'].map(lambda x: x.split('_')[0])\n",
    "test_batches = DataGenerator(test.iloc[::4],subset='test')\n",
    "#test_preds = model.predict_generator(test_batches,verbose=1)\n",
    "test_preds = model.predict(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "i6b3fvcdkziontsaicccbe"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "test_preds1 = model.predict(test_batches,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "sh0y3shixa0y35rre4bsth"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "test_preds\n",
    "test.iloc[::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "78o1o4h37f60nbcq3gv0j79"
   },
   "outputs": [],
   "source": [
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "rjtbtrr3kb811fgnsn3xz2h"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import PIL\n",
    "from PIL import ImageOps\n",
    "def display_mask(i):\n",
    "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
    "    mask = np.argmax(test_preds[i], axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    img = PIL.ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
    "    display(img)\n",
    "\n",
    "\n",
    "# Display results for validation image #10\n",
    "i = 11\n",
    "\n",
    "# Display input image\n",
    "#display(Image(filename=val_input_img_paths[i]))\n",
    "\n",
    "# Display mask predicted by our model\n",
    "display_mask(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xf3pes1mn5iff3b8vu22b"
   },
   "outputs": [],
   "source": [
    "def mask_class_def(i):   \n",
    "    mask_max = np.where(np.max(test_preds[i], axis=-1)==0,0,1)\n",
    "    mask_argmax = np.argmax(test_preds[i], axis=-1)+1\n",
    "    mask0=np.multiply(mask_max,mask_argmax)\n",
    "    return mask0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "oyja3if5xjmybmuwkyoym8"
   },
   "outputs": [],
   "source": [
    "DF=pd.DataFrame()\n",
    "List=[]\n",
    "for i in range(0,1376):\n",
    "    df=pd.DataFrame()\n",
    "    imid=test.ImageId.values[i]\n",
    "    mask=mask_class_def(i)\n",
    "    rles=[]\n",
    "    for k in range(1,5):\n",
    "        rles.append(mask_to_rle(np.where(mask==k,1,0)))\n",
    "    df['ImageId']=pd.Series([str(imid)+'_'+str(m) for m in range(1,5)])\n",
    "    df['EncodedPixels']=rles\n",
    "    DF=pd.concat([DF, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "tr6d9m6cv7ehbly5wp6yng"
   },
   "outputs": [],
   "source": [
    "DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "mdnd185dl1y9fs3cs20u"
   },
   "outputs": [],
   "source": [
    "DF.to_csv('out1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "o81ciitjrcr6qyl83c32e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "notebookId": "1d4e8163-00c6-4227-b503-51e6751e5718"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
